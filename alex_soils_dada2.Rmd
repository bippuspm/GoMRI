---
title: "DADA2"
author: "Paige Varner"
date: "August 19, 2019"
output: html_document
---



# Setup
## Load Libraries
```{r libraries, message=FALSE, warning=FALSE}
library(dada2)
library(readr)
library(stringr)
library(dplyr)
library(tibble)
library(magrittr)
library(phyloseq)
library(ggplot2)

install.packages("reshape")
library(reshape)
```



## Paths, Directories, and Shell Variables

```{r data_path}
demux.dir = file.path("Data/alex_soils/")
scratch.dir = file.path("dada2")
# make directory for output
ps.rds = file.path(scratch.dir, "alex_soils.rds")
silva.ref = "Data/silva_nr_v128_train_set.fa.gz"
silva.species.ref = "Data/silva_species_assignment_v128.fa.gz"

#no data.dir
```



## Checking Files 
Let's make sure that our demultiplexed files are all where we expect them

```{r view_demuxed_files}
list.files(demux.dir)
```



## Filter and Trim

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME.R1.fastq and SAMPLENAME.R2.fastq
fnFs <- sort(list.files(demux.dir, pattern="L001_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(demux.dir, pattern="L001_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME.X.fastq, where X is reverse or forward
# sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
sample.names = fnFs %>% 
  basename %>%
  str_replace("_L001_R1_001.fastq","") 

sample.names = gsub("_.*", "", sample.names)
```


Check work
```{r}
sample.names
print(fnFs)
print(fnRs)
```


## Examine quality profiles of forward and reverse reads

## Forward Read Quality Profile
```{r see-quality-F-all}
plotQualityProfile(fnFs[1:2])
```


## Reverse Read Quality Profile
Now we visualize the quality profile of the reverse reads:
```{r see-quality-F-all}
plotQualityProfile(fnRs[1:2])
```



## Perform filtering and trimming

### Generate filenames for the filtered fastq.gz files.

```{r filt-names}
filt_path <- file.path("dada2/filtered") # Place filtered files in filtered/ subdirectory
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
print(filtFs)
```


### Filter the forward and reverse reads

```{r filter, message=FALSE, warning=FALSE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft=15, truncLen=c(200,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE) # On Windows set multithread=FALSE
head(out)
```



### Tweak Filtered FASTQ list

```{r}
filtFs = filtFs[file_exists(filtFs)]
filtRs = filtRs[file_exists(filtRs)]
filtFs %>% 
  basename %>%
  str_replace("_F_filt.fastq.gz","") ->
  sample.names

sample.names
```



## Learn the Error Rates

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```

Visualize the estimated error rates:
```{r plot-errors, warning=FALSE}
plotErrors(errF, nominalQ=TRUE)
```

 

## Dereplication

```{r dereplicate_tryagain, message=FALSE}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
```

### Rename derep objects

```{r}
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```



## Sample Inference

```{r dada}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs[[1]]
```


## Merge paired reads

```{r merge, message=FALSE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[2]])
```



## Construct sequence table

```{r seqtab}
seqtab_alex_soils <- makeSequenceTable(mergers)
```

How many samples are there?  How many ASVs?
```{r}
dim(seqtab_alex_soils)
```

Let's check the size distribution of the ASVs we have inferred. 
```{r}
table(nchar(getSequences(seqtab_alex_soils)))
```

This removes all sequences that don't fall between ___ bp in length
```{r}
seqtab2_alex_soils=seqtab_alex_soils[,nchar(colnames(seqtab_alex_soils)) %in% seq(276,295)]
```

```{r}
dim(seqtab2_alex_soils)
```



## Remove chimeras

```{r chimeras, message=FALSE}
seqtab_alex_soils.nochim <- removeBimeraDenovo(seqtab2_alex_soils, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab_alex_soils.nochim)
sum(seqtab_alex_soils.nochim)/sum(seqtab2_alex_soils)
```


## Track reads through the pipeline

```{r track}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab_alex_soils.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```


## Assign taxonomy

Now you can assign taxonomy!  You should use this taxonomy reference files : `/data/references/dada/silva_nr_v128_train_set.fa.gz`

```{r taxify}
taxa_alex_soils <- assignTaxonomy(seqtab_alex_soils.nochim, silva.ref, multithread=TRUE)
taxa_alex_soils.print <- taxa_alex_soils # Removing sequence rownames for display only
rownames(taxa_alex_soils.print) <- NULL
head(taxa_alex_soils.print)
```


##Save seq table and tax table as rds
```{r}
saveRDS(seqtab_alex_soils.nochim, file = "seqtab_alex_soils.Rds")
saveRDS(taxa_alex_soils, file = "taxatab_alex_soils.Rds")
```
































# Phyloseq

##Read in tax, seq, and sample tables
```{r}
taxtab_alex_soils = readRDS("taxatab_alex_soils.Rds")
seqtab_alex_soils = readRDS("seqtab_alex_soils.Rds")
samtab_alex_soils = read_tsv("Data/mapfile_alex_soils.txt")
map_1 = file.path("Data/mapfile_alex_soils.txt")
```



## Map Data
First we need to load the map data using phyloseq's `sample_data()` function. `sample_data()` expects the sample identifiers to be rownames, but our map file has them as a column named "#SampleID", so we need to use a function called `column_to_rownames` to convert this column into rownames
```{r load_map}
meta.df.1 = read_tsv(map_1, comment= "#q2")
meta.df.1 = meta.df.1[1:12,]
colnames(meta.df.1)[colnames(meta.df.1) == 'SampleID'] <- 'SampleID'
meta.df.1 = meta.df.1 %>%
  column_to_rownames("SampleID") %>%
  as.data.frame
meta.df.1
```

## Make a Phyloseq Object

```{r make-phyloseq}
otus.1 = otu_table(seqtab_alex_soils, taxa_are_rows=FALSE)
sd.1 = sample_data(meta.df.1)
tax.1 = tax_table(taxtab_alex_soils)
ps_alex_soils <- phyloseq(otus.1,
               sd.1,
               tax.1)
```

And `print` your phyloseq object to be sure it was created correctly
```{r}
ps_alex_soils
```


## Save Phyloseq to RDS

```{r}
saveRDS(ps_alex_soils, file = "phyloseq/ps_alex_soils.rds")
```

## Check Phyloseq RDS

```{r}
loaded.ps = readRDS("phyloseq/ps_alex_soils.rds")
print(loaded.ps)
```


# Session Info
Always print `sessionInfo` for reproducibility!
```{r}
sessionInfo()
```











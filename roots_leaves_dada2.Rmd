---
title: "Roots and leaves DADA2"
author: "Paige Varner"
date: "8/27/2019"
output: html_document
---




# Setup
## Load Libraries
```{r libraries, message=FALSE, warning=FALSE}
library(dada2)
library(readr)
library(stringr)
library(dplyr)
library(tibble)
library(magrittr)
library(phyloseq)
library(ggplot2)

install.packages("reshape")
library(reshape)
```



## Paths, Directories, and Shell Variables

```{r data_path}
demux.dir = file.path("Data/roots_leaves")
scratch.dir = file.path("dada2")
map.file = file.path("Data/GoMRI_mapfile.csv")
# make directory for output
ps.rds = file.path(scratch.dir, "roots_leaves.rds")
silva.ref = "Data/silva_nr_v128_train_set.fa.gz"
silva.species.ref = "Data/silva_species_assignment_v128.fa.gz"

#no data.dir
```



## Checking Files 
Let's make sure that our demultiplexed files are all where we expect them

```{r view_demuxed_files}
list.files(demux.dir)
```



## Filter and Trim

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME.R1.fastq and SAMPLENAME.R2.fastq
fnFs <- sort(list.files(demux.dir, pattern="L001_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(demux.dir, pattern="L001_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME.X.fastq, where X is reverse or forward
# sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
sample.names = fnFs %>% 
  basename %>%
  str_replace("_L001_R1_001.fastq","") 

sample.names = gsub("_.*", "", sample.names)
```


Check work
```{r}
sample.names
print(fnFs)
print(fnRs)
```


## Examine quality profiles of forward and reverse reads

## Forward Read Quality Profile
```{r see-quality-F-all}
plotQualityProfile(fnFs[1:2])
```


## Reverse Read Quality Profile
Now we visualize the quality profile of the reverse reads:
```{r see-quality-F-all}
plotQualityProfile(fnRs[1:2])
```



## Perform filtering and trimming

### Generate filenames for the filtered fastq.gz files.

```{r filt-names}
filt_path <- file.path("dada2/filtered") # Place filtered files in filtered/ subdirectory
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
print(filtFs)
```


### Filter the forward and reverse reads

```{r filter, message=FALSE, warning=FALSE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft=15, truncLen=c(200,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE) # On Windows set multithread=FALSE
head(out)
```



### Tweak Filtered FASTQ list

```{r}
filtFs = filtFs[file_exists(filtFs)]
filtRs = filtRs[file_exists(filtRs)]
filtFs %>% 
  basename %>%
  str_replace("_F_filt.fastq.gz","") ->
  sample.names

sample.names
```



## Learn the Error Rates

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```

Visualize the estimated error rates:
```{r plot-errors, warning=FALSE}
plotErrors(errF, nominalQ=TRUE)
```

 

## Dereplication

```{r dereplicate_tryagain, message=FALSE}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
```

### Rename derep objects

```{r}
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```



## Sample Inference

```{r dada}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs[[1]]
```


## Merge paired reads

```{r merge, message=FALSE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[2]])
```



## Construct sequence table

```{r seqtab}
seqtab_roots_leaves <- makeSequenceTable(mergers)
```

How many samples are there?  How many ASVs?
```{r}
dim(seqtab_roots_leaves)
```

Let's check the size distribution of the ASVs we have inferred. 
```{r}
table(nchar(getSequences(seqtab_roots_leaves)))
```

This removes all sequences that don't fall between ___ bp in length
```{r}
seqtab2_roots_leaves=seqtab_roots_leaves[,nchar(colnames(seqtab_roots_leaves)) %in% seq(276,295)]
```

```{r}
dim(seqtab2_roots_leaves)
```



## Remove chimeras

```{r chimeras, message=FALSE}
seqtab_roots_leaves.nochim <- removeBimeraDenovo(seqtab2_roots_leaves, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab_roots_leaves.nochim)
sum(seqtab_roots_leaves.nochim)/sum(seqtab2_roots_leaves)
```


## Track reads through the pipeline

```{r track}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab_roots_leaves.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```


## Assign taxonomy

Now you can assign taxonomy!  You should use this taxonomy reference files : `/data/references/dada/silva_nr_v128_train_set.fa.gz`

```{r taxify}
taxa_roots_leaves <- assignTaxonomy(seqtab_roots_leaves.nochim, silva.ref, multithread=TRUE)
taxa_roots_leaves.print <- taxa_roots_leaves # Removing sequence rownames for display only
rownames(taxa_roots_leaves.print) <- NULL
head(taxa_roots_leaves.print)
```


##Save seq table and tax table as rds
```{r}
saveRDS(seqtab_roots_leaves.nochim, file = "seqtab_roots_leaves.Rds")
saveRDS(taxa_roots_leaves, file = "taxatab_roots_leaves.Rds")
```























